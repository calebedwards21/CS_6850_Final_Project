{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, year):\n",
    "    \n",
    "    df.rename(columns={'Name of institution': 'Institution Name'}, inplace=True)\n",
    "    df.rename(columns={'Sector name': 'Sector Name'}, inplace=True)\n",
    "    df.rename(columns={'Calendar system': 'Calendar System'}, inplace=True)\n",
    "    \n",
    "    df['Year'] = year[:4]\n",
    "    df.rename(columns={year: 'Cost'}, inplace=True)\n",
    "    \n",
    "    df.drop(['OPEID', 'List C: High percent change tuition and fee indicator', 'Percent change'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "\n",
    "xls_path = './data/*.xls'\n",
    "xlsx_path = './data/*.xlsx'\n",
    "\n",
    "xls_files = glob.glob(xls_path)\n",
    "xlsx_files = glob.glob(xlsx_path)\n",
    "\n",
    "dfs = []\n",
    "years = {0: '2008-09 Tuition and fees', \n",
    "         1: '2009-10 Tuition and fees',\n",
    "         2: '2010-11 Tuition and fees',\n",
    "         3: '2011-12 Tuition and fees',\n",
    "         4: '2012-13 Tuition and fees',\n",
    "         5: '2013-14 Tuition and fees',\n",
    "         6: '2014-15 Tuition and fees'}\n",
    "\n",
    "for file in xls_files: \n",
    "    print(f'File: {file.split(\"/\")[-1]}')\n",
    "    df = pd.read_excel(file, sheet_name='TuitionChange')         \n",
    "    \n",
    "    for k, year in years.items():\n",
    "        if year in df.columns:\n",
    "            df = process_data(df, year)\n",
    "            df.drop([years[k+2]], axis=1, inplace=True)\n",
    "    \n",
    "    print(f'Empty Counts: {df.isnull().sum()}\\n')\n",
    "    dfs.append(df)\n",
    "    \n",
    "for file in xlsx_files:\n",
    "    print(f'File: {file.split(\"/\")[-1]}')\n",
    "    df1 = pd.read_excel(file, sheet_name='TuitionChange') \n",
    "    df2 = df1.copy()\n",
    "    \n",
    "    for k, year in years.items():\n",
    "        if year in df1.columns:\n",
    "            df1.drop([years[k+2]], axis=1, inplace=True)\n",
    "            df1 = process_data(df1, year)\n",
    "            df2.drop([year], axis=1, inplace=True)\n",
    "            df2 = process_data(df2, years[k+2])\n",
    "    \n",
    "    print(f'Empty Counts 1: {df1.isnull().sum()}\\n')      \n",
    "    dfs.append(df1)\n",
    "    print(f'Empty Counts 2: {df2.isnull().sum()}\\n')\n",
    "    dfs.append(df2)\n",
    "        \n",
    "dfs[-2], dfs[-3] = dfs[-3], dfs[-2]\n",
    "\n",
    "data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = data[data['Cost'].isnull()].groupby('Institution Name').size().sort_values(ascending=False)\n",
    "print(null_data)\n",
    "\n",
    "null_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in null values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "clean_data = data.copy()\n",
    "\n",
    "string_cols = ['Institution Name', 'State']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in string_cols:\n",
    "    clean_data.loc[:, col + ' Encoded'] = encoder.fit_transform(clean_data.loc[:, col])\n",
    "    \n",
    "data_missing = clean_data[clean_data['Cost'].isnull()]\n",
    "data_complete = clean_data.dropna()\n",
    "\n",
    "X_train = data_complete[['Year', 'UnitID', 'Institution Name Encoded', 'State Encoded']]\n",
    "y_train = data_complete['Cost']\n",
    "\n",
    "X_test = data_missing[['Year', 'UnitID', 'Institution Name Encoded', 'State Encoded']]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "clean_data.loc[clean_data['Cost'].isnull(), 'Cost'] = predicted_values\n",
    "clean_data['Predicted'] = 0\n",
    "clean_data['Year'] = pd.to_datetime(clean_data['Year'])\n",
    "\n",
    "print(clean_data['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = clean_data['Year'].dt.year.min()\n",
    "end_year = clean_data['Year'].dt.year.max()\n",
    "years_range = range(start_year, end_year + 1)\n",
    "\n",
    "institutions_missing_years = {}\n",
    "colleges_with_gaps = {}\n",
    "count = 0\n",
    "\n",
    "grouped = clean_data.groupby(['Institution Name', 'State', 'UnitID'])\n",
    "print(f'Total Institutions : {len(grouped)}')\n",
    "print('Institutions Yearly Data Count')\n",
    "print(grouped['Year'].nunique().value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "institutions_with_gaps = []\n",
    "\n",
    "for (name, state, unitid), group in grouped:\n",
    "    years_present = group['Year'].dt.year\n",
    "    gaps = years_present.diff().fillna(1).ne(1)\n",
    "    \n",
    "    if gaps.any():\n",
    "        institutions_with_gaps.append((name, state, unitid, list(years_present)))\n",
    "\n",
    "count = 0\n",
    "for institution in institutions_with_gaps:\n",
    "    if len(institution[3]) > 3:\n",
    "        print(f\"Institution: {institution[0]}, State: {institution[1]}, ID: {institution[2]}\")\n",
    "        print(f\"Existing Years: {institution[3]}\")\n",
    "        print()\n",
    "        count += 1\n",
    "        \n",
    "print(f'Fillable Years : {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do the next section if worth creating 387 rows from step above...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = clean_data['Institution Name'].unique()\n",
    "\n",
    "# rows = []\n",
    "\n",
    "# earliest = clean_data['Year'].unique().min()\n",
    "# latest = clean_data['Year'].unique().max()\n",
    "# years = clean_data['Year'].unique()\n",
    "\n",
    "# for name in names:\n",
    "#     name_data = clean_data.loc[clean_data['Institution Name'] == name]\n",
    "    \n",
    "#     if len(name_data) < 5:\n",
    "#         continue\n",
    "    \n",
    "#     for year in years:\n",
    "#         if year not in name_data['Year'].values:\n",
    "#             if year == earliest or year == latest:\n",
    "#                 continue\n",
    "            \n",
    "#             print(name_data)\n",
    "            \n",
    "#             prev_row = name_data.loc[name_data['Year'] == year - pd.DateOffset(years=1)]\n",
    "#             next_row = name_data.loc[name_data['Year'] == year + pd.DateOffset(years=1)]\n",
    "            \n",
    "#             if prev_row.empty:\n",
    "#                 prev_row = name_data.loc[name_data['Year'] == year - pd.DateOffset(years=2)]\n",
    "        \n",
    "#             if next_row.empty:\n",
    "#                 next_row = name_data.loc[name_data['Year'] == year + pd.DateOffset(years=2)]\n",
    "                                                                                   \n",
    "#             prev_row = prev_row.iloc[0]\n",
    "#             next_row = next_row.iloc[0]\n",
    "#             cost = (prev_row ['Cost'] + next_row['Cost']) / 2 \n",
    "#             row = prev_row\n",
    "#             row['Year'] = year\n",
    "#             row['Cost'] = cost\n",
    "#             row['Predicted'] = 1\n",
    "#             rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = pd.concat([clean_data] + rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "pred_rows = []\n",
    "\n",
    "for (name, state, unitid), institution_data in grouped:\n",
    "    df = institution_data.copy()\n",
    "    pred = df.iloc[-1].copy()\n",
    "    \n",
    "    if df['Year'].dt.year.diff().fillna(1).ne(1).any() or len(df) < 4:\n",
    "        continue\n",
    "    \n",
    "    df.set_index('Year', inplace=True)\n",
    "    df.index = pd.DatetimeIndex(df.index, freq='infer')\n",
    "\n",
    "    forecast = ARIMA(df['Cost'], order=(1,0,0)).fit().forecast(steps=3)\n",
    "    \n",
    "    for idx, cost in enumerate(forecast):\n",
    "        pred_row = pred.copy()\n",
    "        pred_row['Predicted'] = 1 \n",
    "        pred_row['Cost'] = cost\n",
    "        pred_row['Year'] = pred_row['Year'] + pd.DateOffset(years=idx+1)\n",
    "        pred_rows.append(pred_row)\n",
    "\n",
    "print(len(pred_rows))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.concat([clean_data] + pred_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change year to an integer\n",
    "clean_data['Year'] = clean_data['Year'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Define your connection parameters\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'tuition'\n",
    "db_user = 'my_user'\n",
    "db_password = 'password'\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=db_host,\n",
    "        port=db_port,\n",
    "        database=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password\n",
    "    )\n",
    "    print(\"Connected to the database\")\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    \n",
    "    db_version = cursor.fetchone()\n",
    "    print(\"PostgreSQL database version:\", db_version)\n",
    "    \n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to PostgreSQL:\", e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS Tuition (\n",
    "    institution VARCHAR(100) NOT NULL,\n",
    "    year INTEGER NOT NULL,\n",
    "    sector INTEGER NOT NULL,\n",
    "    sector_name VARCHAR(100) NOT NULL,\n",
    "    state VARCHAR(25) NOT NULL,\n",
    "    high_cost BOOLEAN NOT NULL,\n",
    "    low_cost BOOLEAN NOT NULL,\n",
    "    cost INTEGER NOT NULL\n",
    ");\n",
    "'''\n",
    "\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public';  -- Assuming tables are in the public schema\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch the results\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "for row in rows:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "DATABASE_URL = \"postgresql://my_user:password@localhost:5432/tuition\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "table_name = 'Tuition'\n",
    "clean_data.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM Tuition LIMIT 100;\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
