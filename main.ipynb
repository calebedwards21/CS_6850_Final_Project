{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, year):\n",
    "    \n",
    "    df.rename(columns={'Name of institution': 'Institution Name'}, inplace=True)\n",
    "    df.rename(columns={'Sector name': 'Sector Name'}, inplace=True)\n",
    "    df.rename(columns={'Calendar system': 'Calendar System'}, inplace=True)\n",
    "    \n",
    "    df['Year'] = year[:4]\n",
    "    df.rename(columns={year: 'Cost'}, inplace=True)\n",
    "    \n",
    "    df.drop(['OPEID', 'List C: High percent change tuition and fee indicator', 'Percent change'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "\n",
    "xls_path = './data/*.xls'\n",
    "xlsx_path = './data/*.xlsx'\n",
    "\n",
    "xls_files = glob.glob(xls_path)\n",
    "xlsx_files = glob.glob(xlsx_path)\n",
    "\n",
    "dfs = []\n",
    "years = {0: '2008-09 Tuition and fees', \n",
    "         1: '2009-10 Tuition and fees',\n",
    "         2: '2010-11 Tuition and fees',\n",
    "         3: '2011-12 Tuition and fees',\n",
    "         4: '2012-13 Tuition and fees',\n",
    "         5: '2013-14 Tuition and fees',\n",
    "         6: '2014-15 Tuition and fees'}\n",
    "\n",
    "for file in xls_files: \n",
    "    print(f'File: {file.split(\"/\")[-1]}')\n",
    "    df = pd.read_excel(file, sheet_name='TuitionChange')         \n",
    "    \n",
    "    for k, year in years.items():\n",
    "        if year in df.columns:\n",
    "            df = process_data(df, year)\n",
    "            df.drop([years[k+2]], axis=1, inplace=True)\n",
    "    \n",
    "    print(f'Empty Counts: {df.isnull().sum()}\\n')\n",
    "    dfs.append(df)\n",
    "    \n",
    "for file in xlsx_files:\n",
    "    print(f'File: {file.split(\"/\")[-1]}')\n",
    "    df1 = pd.read_excel(file, sheet_name='TuitionChange') \n",
    "    df2 = df1.copy()\n",
    "    \n",
    "    for k, year in years.items():\n",
    "        if year in df1.columns:\n",
    "            df1.drop([years[k+2]], axis=1, inplace=True)\n",
    "            df1 = process_data(df1, year)\n",
    "            df2.drop([year], axis=1, inplace=True)\n",
    "            df2 = process_data(df2, years[k+2])\n",
    "    \n",
    "    print(f'Empty Counts 1: {df1.isnull().sum()}\\n')      \n",
    "    dfs.append(df1)\n",
    "    print(f'Empty Counts 2: {df2.isnull().sum()}\\n')\n",
    "    dfs.append(df2)\n",
    "        \n",
    "dfs[-2], dfs[-3] = dfs[-3], dfs[-2]\n",
    "\n",
    "data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = data[data['Cost'].isnull()].groupby('Institution Name').size().sort_values(ascending=False)\n",
    "print(null_data)\n",
    "\n",
    "null_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in null values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "clean_data = data.copy()\n",
    "\n",
    "string_cols = ['Institution Name', 'State']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in string_cols:\n",
    "    clean_data.loc[:, col + ' Encoded'] = encoder.fit_transform(clean_data.loc[:, col])\n",
    "    \n",
    "data_missing = clean_data[clean_data['Cost'].isnull()]\n",
    "data_complete = clean_data.dropna()\n",
    "\n",
    "X_train = data_complete[['Year', 'UnitID', 'Institution Name Encoded', 'State Encoded']]\n",
    "y_train = data_complete['Cost']\n",
    "\n",
    "X_test = data_missing[['Year', 'UnitID', 'Institution Name Encoded', 'State Encoded']]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "clean_data.loc[clean_data['Cost'].isnull(), 'Cost'] = predicted_values\n",
    "clean_data['Predicted'] = 0\n",
    "clean_data['Year'] = pd.to_datetime(clean_data['Year'])\n",
    "\n",
    "clean_data['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = clean_data['Year'].dt.year.min()\n",
    "end_year = clean_data['Year'].dt.year.max()\n",
    "years_range = range(start_year, end_year + 1)\n",
    "\n",
    "institutions_missing_years = {}\n",
    "colleges_with_gaps = {}\n",
    "count = 0\n",
    "\n",
    "grouped = clean_data.groupby(['Institution Name', 'State', 'UnitID'])\n",
    "print(f'Total Institutions : {len(grouped)}')\n",
    "print('Institutions Yearly Data Count')\n",
    "print(grouped['Year'].nunique().value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "institutions_with_gaps = []\n",
    "\n",
    "for (name, state, unitid), group in grouped:\n",
    "    years_present = group['Year'].dt.year\n",
    "    gaps = years_present.diff().fillna(1).ne(1)\n",
    "    \n",
    "    if gaps.any():\n",
    "        institutions_with_gaps.append((name, state, unitid, list(years_present)))\n",
    "\n",
    "count = 0\n",
    "for institution in institutions_with_gaps:\n",
    "    if len(institution[3]) > 3:\n",
    "        print(f\"Institution: {institution[0]}, State: {institution[1]}, ID: {institution[2]}\")\n",
    "        print(f\"Existing Years: {institution[3]}\")\n",
    "        print()\n",
    "        count += 1\n",
    "        \n",
    "print(f'Fillable Years : {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do the next section if worth creating 387 rows from step above...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = clean_data['Institution Name'].unique()\n",
    "\n",
    "# rows = []\n",
    "\n",
    "# earliest = clean_data['Year'].unique().min()\n",
    "# latest = clean_data['Year'].unique().max()\n",
    "# years = clean_data['Year'].unique()\n",
    "\n",
    "# for name in names:\n",
    "#     name_data = clean_data.loc[clean_data['Institution Name'] == name]\n",
    "    \n",
    "#     if len(name_data) < 5:\n",
    "#         continue\n",
    "    \n",
    "#     for year in years:\n",
    "#         if year not in name_data['Year'].values:\n",
    "#             if year == earliest or year == latest:\n",
    "#                 continue\n",
    "            \n",
    "#             print(name_data)\n",
    "            \n",
    "#             prev_row = name_data.loc[name_data['Year'] == year - pd.DateOffset(years=1)]\n",
    "#             next_row = name_data.loc[name_data['Year'] == year + pd.DateOffset(years=1)]\n",
    "            \n",
    "#             if prev_row.empty:\n",
    "#                 prev_row = name_data.loc[name_data['Year'] == year - pd.DateOffset(years=2)]\n",
    "        \n",
    "#             if next_row.empty:\n",
    "#                 next_row = name_data.loc[name_data['Year'] == year + pd.DateOffset(years=2)]\n",
    "                                                                                   \n",
    "#             prev_row = prev_row.iloc[0]\n",
    "#             next_row = next_row.iloc[0]\n",
    "#             cost = (prev_row ['Cost'] + next_row['Cost']) / 2 \n",
    "#             row = prev_row\n",
    "#             row['Year'] = year\n",
    "#             row['Cost'] = cost\n",
    "#             row['Predicted'] = 1\n",
    "#             rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = pd.concat([clean_data] + rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data.copy()\n",
    "data_df['Predicted'] = 0\n",
    "data_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_linearity(df):\n",
    "    results = {}\n",
    "    for (name, id), group in df.groupby(['Institution Name', 'UnitID']):\n",
    "        X = group['Year'].values.reshape(-1, 1)\n",
    "        y = group['Cost'].values\n",
    "        \n",
    "        if len(y) < 4:\n",
    "            continue\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Check linearity by comparing R-squared\n",
    "        results[id] = model.score(X, y)\n",
    "        \n",
    "    return results\n",
    "\n",
    "linear = 0\n",
    "linear_ids = []\n",
    "non_linear = 0\n",
    "linearity = check_linearity(data_df)\n",
    "for k, v in linearity.items():\n",
    "    if v < 0.7:\n",
    "        non_linear+=1\n",
    "    else:\n",
    "        linear+=1\n",
    "        linear_ids.append(k)\n",
    "        \n",
    "print(f'Linear : {linear}, Non Linear : {non_linear}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_df = data_df[data_df['UnitID'].isin(linear_ids)]\n",
    "linear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mses = {}\n",
    "future_rows = []\n",
    "for (name, id), group in linear_df.groupby(['Institution Name', 'UnitID']):  \n",
    "    # Test model\n",
    "    X = group['Year'].values.reshape(-1, 1) \n",
    "    y = group['Cost'].values\n",
    "    \n",
    "    if len(y) < 4:\n",
    "        continue\n",
    "    \n",
    "    X_train = X[:-1]\n",
    "    y_train = y[:-1]\n",
    "    X_test = X[-1].reshape(1, -1)\n",
    "    y_test = y[-1].reshape(1, -1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train) \n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # print(f'Pred : {y_pred}, Actual : {y_test}')\n",
    "    mses[id] = mse\n",
    "    \n",
    "    # future predictions\n",
    "    year = int(X_test[0][0]) + 1\n",
    "    future_year = np.array([[year]])\n",
    "    future_pred = model.predict(future_year)\n",
    "    row = group.iloc[0].copy()\n",
    "    row['Year'] = str(year)\n",
    "    row['Cost'] = future_pred[0]\n",
    "    row['Predicted'] = 1\n",
    "    future_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = any(series.isna().any() for series in future_rows)\n",
    "\n",
    "if has_nan:\n",
    "    print(\"At least one Series contains NaN values.\")\n",
    "else:\n",
    "    print(\"No Series contain NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = sum(mses.values()) / len(mses)\n",
    "\n",
    "print(f'Average MSE : {average}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(future_rows)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['Year'] = pd.to_datetime(pred_df['Year'])\n",
    "\n",
    "pred_df['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# pred_rows = []\n",
    "\n",
    "# for (name, state, unitid), institution_data in grouped:\n",
    "#     df = institution_data.copy()\n",
    "#     pred = df.iloc[-1].copy()\n",
    "    \n",
    "#     if df['Year'].dt.year.diff().fillna(1).ne(1).any() or len(df) < 4:\n",
    "#         continue\n",
    "    \n",
    "#     df.set_index('Year', inplace=True)\n",
    "#     df.index = pd.DatetimeIndex(df.index, freq='infer')\n",
    "\n",
    "#     forecast = ARIMA(df['Cost'], order=(1,0,0)).fit().forecast(steps=3)\n",
    "    \n",
    "#     for idx, cost in enumerate(forecast):\n",
    "#         pred_row = pred.copy()\n",
    "#         pred_row['Predicted'] = 1 \n",
    "#         pred_row['Cost'] = cost\n",
    "#         pred_row['Year'] = pred_row['Year'] + pd.DateOffset(years=idx+1)\n",
    "#         pred_rows.append(pred_row)\n",
    "\n",
    "# print(len(pred_rows))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data = pd.concat([clean_data] + pred_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to psql client: docker run -it --rm --network docker_my_network postgres:16 psql -h postgres -U postgres\n",
    "# Use database: \\c project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Define your connection parameters\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'project'\n",
    "db_user = 'postgres'\n",
    "db_password = 'password'\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=db_host,\n",
    "        port=db_port,\n",
    "        database=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password\n",
    "    )\n",
    "    print(\"Connected to the database\")\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    \n",
    "    db_version = cursor.fetchone()\n",
    "    print(\"PostgreSQL database version:\", db_version)\n",
    "    \n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to PostgreSQL:\", e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.drop(columns=['State Encoded', 'Institution Name Encoded'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_data.columns)\n",
    "print(pred_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "DATABASE_URL = \"postgresql://postgres:password@localhost:5432/project\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "table_name = 'tuition'\n",
    "clean_data.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "pred_df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM tuition LIMIT 10;\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
